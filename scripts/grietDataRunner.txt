# don't run this file!
# transpose_input.txt is a tab separated file containing 1
# experiment per line. The first value of each line is the name
# of the experiment, followed by the peptides of the experiment.
#
# output.txt is a tab separated file ontaining 1 taxonomic node
# per line. The first value of each line is the name of the taxon,
# follow by the number of occurences in the experiment corresponding
# with that column

# First transpose in excel and paste in new document.
# You can use Paste Special Transpose in Excel to do the transformation.
# A fairly recent version of Excel is needed because of the low maximum
# number of columns in older versions.
# Split the input into separate files.
# The filename is the name of the experiment.
gawk '{print > $1".input";close($1);}' transpose_input.txt
for f in *.input; do gsed -i "s/\t/\n/g" $f; gsed -i "1d" $f; done

# Run this on the server
for f in *.input; do ./backend/scripts/batchSearch.sh $f $f true false true".output"; done
mkdir output
mv *.output output
tar -zcvf output.tar.gz output
mv output.tar.gz public

# Run this on the client
# Count the number of occurences per taxon
for f in *.output; do cat $f | sed '1d' | sed 's/^[^,]*,*//' | sed 's/,""//g' | sort | uniq -c | sed 's/^ *\([0-9]*\) \(.*\)$/\2;\1/' > $f".grouped"; done

# Create a "masterfile" containing the combined taxa of all experiments
cat *.grouped | sed 's/;.*//' | sort | uniq > masterfile.txt

# Merge each file with the masterfile.
for f in *.grouped; do join -t";" -a1 -o "0 2.2" -e "0" masterfile.txt $f | sed "s/0;/root;/" > $f".merged" ; done
sed "s/^$/root/" masterfile.txt > merge.txt

# Merge all files
echo -n ";" > files.txt ; for f in *.merged; do join -t ";" merge.txt $f > temp.txt ; cp temp.txt merge.txt ; echo -n $f";" >> files.txt ; done; rm temp.txt

# Add header row
sed "s/.input.output.grouped.merged//g" files.txt > output.txt ; cat merge.txt >> output.txt; rm files.txt merge.txt



# cumulative
cp output.txt test.txt
head -1 test.txt > header.txt
gsed -i "1d" test.txt
# manually remove any name with [ or ] in it
tail -r test.txt > test.txt.reverse
awk -f cumulative.awk test.txt.reverse | tail -r > test.txt.sum
cat header.txt test.txt.sum > sum.txt

# awk script
BEGIN{
    FS=";"
    max = 0
    fields = 0;
}
{
    max = NR
    fields = NF
    names[NR]=$1
    for (i = 2; i <= NF; i++) {
        originals[$1"_"i] = $i
        sum[$1"_"i] = 0
    }
    for(i = 1; i <= max; i++) {
        if (match(names[i], "^"$1) != 0 || $1 == "root") {
            for (j = 2; j <= NF; j++) {
                sum[$1"_"j] += originals[names[i]"_"j]
            }
        }
    }
}
END{
    for (i = 1; i <= max; i++) {
        printf "%s", names[i]
        for (j = 2; j <= NF; j++) {
            printf ";%s", sum[names[i]"_"j]
        }
        printf "\n"
    }
}
